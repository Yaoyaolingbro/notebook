# chap01 Supervised Learning of Behaviors
# Terminology
![20241029201146.png](graph/20241029201146.png)

å…ˆæ¥å›é¡¾ä¸€ä¸‹[Preliminaries](./index.md#preliminaries)ä¸­çš„å†…å®¹ï¼Œä»‹ç»ä¸€äº›ç¬¦å·â€”â€”

- $o_t$ : observation at time $t$
- $a_t$ : action at time $t$
- $s_t$ : state at time $t$
- $\pi_\theta(a_t|o_t)$ ï¼špolicy

ä»€ä¹ˆæ˜¯observationå‘¢ï¼Ÿè¿™å°±å¼•å…¥äº†ä¸€ä¸ªè¯é¢˜â€”â€”æˆ‘ä»¬æœ‰æ—¶å€™å¹¶ä¸èƒ½è§‚å¯Ÿåˆ°å…¨éƒ¨çš„stateã€‚

æ¯”å¦‚è¯´ï¼Œåœ¨å¼€è½¦çš„æ—¶å€™ï¼Œstateåº”è¯¥åŒ…å«å…¶ä»–æ‰€æœ‰è½¦è¾†çš„ä½ç½®ã€é€Ÿåº¦ç­‰ç­‰ã€‚ä½†ä»è½¦çª—ä¸Šçš„æ‘„åƒå¤´æ‹ä¸€å¼ ç…§ç‰‡ï¼Œæˆ‘ä»¬æ˜¾ç„¶ä¸èƒ½è·å¾—å…¨éƒ¨çš„ä¿¡æ¯ï¼›ç›¸åï¼Œç»™å®šstateï¼Œæˆ‘ä»¬å¯ä»¥å®Œå…¨ç»™å‡ºè¿™å¼ ç…§ç‰‡ã€‚è¿™æ ·çš„ç…§ç‰‡å°±æ˜¯**observation**ã€‚

åœ¨æœ¬ç¬”è®°çš„ç»å¤§éƒ¨åˆ†æ—¶å€™ï¼Œæˆ‘ä»¬æ€»æ˜¯å¯ä»¥å¿½ç•¥stateå’Œobservationä¹‹é—´çš„å·®åˆ«ï¼›ä½†æœ‰å°‘æ•°çš„æƒ…å†µï¼Œæˆ‘ä»¬å¿…é¡»è¦åŒºåˆ†å®ƒä»¬ï¼Œåˆ°æ—¶å€™ä¼šæ˜ç¡®åœ°è¯´æ˜ã€‚

æˆ‘ä»¬è®¤ä¸ºstateæ˜¯**å®Œå¤‡çš„**ã€‚ä»€ä¹ˆå«åšå®Œå¤‡ï¼Ÿå…¶å®å°±æ˜¯è¯´ï¼Œåœ¨å·²çŸ¥ $s_t$ çš„æ—¶å€™ï¼Œ $s_{t-1}$ ä¸èƒ½æä¾›å…³äº $s_{t+1}$ çš„æ›´å¤šä¿¡æ¯ã€‚ä¹Ÿå°±æ˜¯

$$
s_{t-1}\perp s_{t+1}|s_t
$$

æ»¡è¶³è¿™æ ·çš„æ¡ä»¶åï¼Œæˆ‘ä»¬å°±å¯ä»¥å‘ç°ï¼Œ $s_{t+1}$ åªä¸ $s_t,a_t$ æœ‰å…³ï¼Œè€Œè¿™åˆåªå’Œç¯å¢ƒæœ‰å…³ï¼ˆæ³¨æ„å’Œpolicyæ— å…³ï¼Œå› ä¸º $a_t$ å·²ç»ç»™å‡ºäº†ï¼‰ã€‚è¿™å¯ä»¥å«åšdynamicsï¼Œä¹Ÿå¯ä»¥å«åš**transition probability**ï¼š

$$
s_{t+1}\sim p(s_{t+1}|s_t,a_t) \qquad (\text{determined by env})
$$

æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œåœ¨è¿™æ ·çš„ä¸€ç³»åˆ—å‡è®¾åï¼Œæˆ‘ä»¬å¯ä»¥æ„é€ ä¸€ä¸ªMarkov Chainï¼Œæ»¡è¶³Markov Propertyã€‚å¦‚å›¾æ‰€ç¤ºã€‚

![](./assets/2-1.png)

æ³¨æ„ï¼Œåœ¨ç»™å®š$a_2$çš„æ—¶å€™ï¼Œ$a_3$æ˜¯ç‹¬ç«‹äº$a_1$çš„ï¼Œå¹¶ä¸”$s_1$ä¸ä¼šæä¾›é¢å¤–çš„ä¿¡æ¯ã€‚

è¯·ä¸è¦confounding $O \& S$, $O$æ˜¯agentçš„è§‚å¯Ÿï¼Œ$S$æ˜¯agentçš„çŠ¶æ€ã€‚

æ—©æœŸçš„å•çº¯çš„ç›‘ç£å­¦ä¹ å¹¶ä¸èƒ½å¾ˆå¥½çš„åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸Šåº”ç”¨çš„åŸå› æ˜¯ï¼šIID(Independent and Identically Distributed)å‡è®¾ä¸æˆç«‹.

> å³å½“å‰è¾“å‡ºç»“æœå¯èƒ½å½±å“ç€ä¸‹ä¸€æ¬¡è¾“å‡ºç»“æœçš„å‡†ç¡®æ€§ã€‚

![20241029202348.png](graph/20241029202348.png)

ä½†æ˜¯å½“è‹±ä¼Ÿè¾¾æŠŠæ•°æ®å †çš„è¶³å¤Ÿå¤šçš„æ—¶å€™ï¼Œè¿˜æ˜¯workäº†çš„ã€‚

è§£å†³çš„åŠæ³•å¯ä»¥æ˜¯ï¼šå¢åŠ æ•°æ®é‡ï¼Œå¼ºå¤§çš„æ¨¡å‹ï¼Œmulti-task learningï¼ˆexoticï¼‰ã€‚
![20241029202631.png](graph/20241029202631.png)

# Imitation Learning

æˆ‘ä»¬æ¥ä»‹ç»æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªRLâ€œç®—æ³•â€â€”â€”Imitation Learningã€‚

Imitation Learning çš„æ€è·¯å¾ˆç®€å•ï¼šæˆ‘ä»¬æ‰¾ä¸€ä¸ªä¸“å®¶æ¥label dataï¼Œæ„å»ºä¸€ä¸ªæ•°æ®é›†
$$
\mathcal{D}=\{s,a\}
$$
ç„¶åï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä½¿å¾—
$$
\theta^\star = \argmax_{\theta}\log \pi_\theta(a=\pi^\star(s)|s)
$$
å…¶ä¸­ï¼Œ $\pi^\star$ æ˜¯ä¸“å®¶çš„ç­–ç•¥ã€‚éœ€è¦æ³¨æ„ï¼Œè¿™é‡Œå®Œå…¨æ²¡æœ‰RLçš„çŸ¥è¯†ï¼Œåªæ˜¯æ™®é€šçš„DLé—®é¢˜ã€‚è¿™ä¹Ÿæœ‰æ—¶å€™è¢«å«åšbehavior cloningã€‚

æ¨¡å‹çš„å®ç°å¯ä»¥æ˜¯DLä¸­çš„å¾ˆå¤šç±»å‹çš„ç½‘ç»œã€‚æ¯”å¦‚è¯´CNN,VAE,ç”šè‡³diffusion modelsã€‚æ›´è¿›ä¸€æ­¥ï¼Œæœ‰äº›ç ”ç©¶è€ƒè™‘ä¸“å®¶çš„Non-Markovæ€§è´¨ï¼Œå› æ­¤ä½¿ç”¨RNNæ¥å»ºæ¨¡ã€‚å½“ç„¶ï¼Œå¾ˆå¤šç»éªŒè¯æ˜æœ‰â€œå†å²â€çš„æ¨¡å‹ä¸ä¸€å®šæ¯”â€œæ— å†å²â€çš„æ¨¡å‹å¥½ã€‚

# Behavior Cloning Analysis

ç›´è§‚ä¸Šï¼Œbahavior cloningåº”è¯¥**å¤±è´¥**ã€‚

æ¯”å¦‚è¯´ï¼Œä¸€ä¸ªæ¨¡å‹åœ¨â€œèµ°é’¢ä¸â€ï¼Œå®ƒæ¯ä¸€æ­¥æœ‰98%çš„æ¦‚ç‡èµ°åœ¨æ­£ç¡®çš„é“è·¯ä¸Šã€‚è¿™æ ·çš„æ¨¡å‹å¦‚æœä»æˆ‘ä»¬è®­ç»ƒæ•°æ®çš„è§’åº¦æ¥çœ‹ï¼Œå·²ç»æ˜¯ä¸€ä¸ªå¾ˆä¸é”™çš„DLæ¨¡å‹äº†ã€‚ä½†æ˜¯å‡è®¾æ¨¡å‹å†³ç­–100æ­¥ï¼Œé‚£ä¹ˆåªæœ‰13%å·¦å³çš„æ¦‚ç‡å®ƒä¾ç„¶ä¿æŒåœ¨ä¸“å®¶çš„é“è·¯ä¸Šï¼

ä¸‹é¢ç»™å‡ºäº†ä¸€äº›æ•°å­¦ä¸Šçš„åˆ†æã€‚å®ƒä»¬çš„ä¸»è¦ç›®çš„éƒ½æ˜¯ä¸ºäº†boundä½behavior cloingçš„æ¨¡å‹å’Œä¸“å®¶ä¹‹é—´çš„å·®è·ã€‚

## Notations
- $a=\pi^{\star}(s)$ : the expert policy gives $a$ when the state is $s$
- $\pi_\theta$ : the policy we are trying to learn
- $p_{\pi_\theta}(s_t)$ : the probability of being at state $s_t$ at time $t$ if we follow $\pi_\theta$ . 
    - **é‡è¦æç¤º**: $p_{\pi_\theta}(s_t)$ çš„è¿™ä¸ª $p_{\pi_\theta}$ åˆ†å¸ƒå’Œ $p_{\pi_\theta}(s_{t+1})$ çš„è¿™ä¸ª $p_{\pi_\theta}$ åˆ†å¸ƒå¯ä¸æ˜¯ä¸€ä¸ªåˆ†å¸ƒï¼ä¸€ä¸ªæ˜¯åœ¨ $t$ æ—¶çš„åˆ†å¸ƒï¼Œä¸€ä¸ªæ˜¯åœ¨ $t+1$ æ—¶çš„åˆ†å¸ƒã€‚ çš„ç¡®â€”â€”you are on the road ğŸ˜ˆ
- Use $|p_1-p_2|$ to denote the total variance distance between $p_1$ and $p_2$ : $|p_1-p_2|=\sum_{x}|p_1(x)-p_2(x)|$

## Distribution Distance

> Relaxï¼Œåªæ˜¯ä¸ºäº†è¯æ˜ä¸Šç•Œçš„é—®é¢˜ã€‚

**Assumptions.**

- $\forall (a,s), \pi_\theta(a\ne \pi^{\star}(s)|s)\le \epsilon$

**Conclusion**: å¯¹ä»»æ„çš„ $t$ ,

$$
\sum_{s_t}|p_{\pi_\theta}(s_t)-p_{\pi^{\star}}(s_t)|\le 2\epsilon t.
$$


**Proof**. **å½’çº³**åœ¨è¿™ç±»é—®é¢˜æ˜¯å¾ˆå¸¸è§çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¯•ç€æŠŠ $t+1$ æ—¶åˆ»å’Œ $t$ æ—¶åˆ»çš„è¡¨è¾¾å¼è”ç³»èµ·æ¥ï¼š

$$
\left|p_{\pi_\theta}(s_{t+1})-p_{\pi^\star}(s_{t+1})\right|=\left|\sum_{s_t,a_t}p(s_{t+1}|s_t,a_t)\pi_\theta(a_t|s_t)p_{\pi_\theta}(s_t)-\sum_{s_t}p(s_{t+1}|s_t,\pi^\star(s_t))p_{\pi^\star}(s_t)\right|.
$$

$$
=\left|\sum_{s_t}\left(\sum_{a_t\ne \pi^\star(s_t)}p(s_{t+1}|s_t,a_t)\pi_\theta(a_t|s_t)+p(s_{t+1}|s_t,\pi^\star(s_t))\pi_\theta(\pi^\star(s_t)|s_t)\right)p_{\pi_\theta}(s_t)-\sum_{s_t}p(s_{t+1}|s_t,\pi^\star(s_t))p_{\pi^\star}(s_t)\right|.
$$

$$
\le \epsilon \sum_{s_t}p_{\pi_\theta}(s_t)+\sum_{s_t}p(s_{t+1}|s_t,\pi^\star(s_t))p_{\pi_\theta}(s_t)\cdot \epsilon+\sum_{s_t}p(s_{t+1}|s_t,\pi^\star(s_t))\left|p_{\pi_\theta}(s_t)-p_{\pi^\star}(s_t)\right|
$$

$$
=\epsilon+\epsilon \sum_{s_t}p_{\pi_\theta}(s_t)p(s_{t+1}|s_t,\pi^\star(s_t))+\sum_{s_t}p(s_{t+1}|s_t,\pi^\star(s_t))\left|p_{\pi_\theta}(s_t)-p_{\pi^\star}(s_t)\right|.
$$

å¯¹ $s_{t+1}$ æ±‚å’Œå³è¯ã€‚

*Side Note.* Homework 1 çš„ Problem 1 å®é™…ä¸Šç»™å‡ºäº†ä¸€ä¸ªå¼±åŒ–çš„æ¡ä»¶ï¼Œä¾ç„¶å¯ä»¥ç»™å‡ºåŒæ ·çš„ç»“è®ºï¼š

$$
\mathbb{E}_{s_t\sim p_{\pi^\star}}[\pi_\theta(a_t\ne \pi^{\star}(s_t)|s_t)]\le \epsilon.
$$

## The total cost

**Assumptions.**
- $\mathbb{E}_{s_t\sim p_{\pi^\star}}[\pi_\theta(a_t\ne \pi^{\star}(s_t)|s_t)]\le \epsilon.$

å¦‚æœæˆ‘ä»¬å®šä¹‰ $c_t$ æ˜¯ **cost function**ï¼š
$$
c_t(s_t,a_t)=\begin{cases}0&,a_t=\pi^{\star}(s_t)\\1&,\text{otherwise}\end{cases}.
$$

**Conclusion**: 

$$
S=\sum_{t\le T} E_{s_t\sim p_{\pi_\theta}}[c_t(s_t,a_t)]=\mathcal{O}(\epsilon T^2).
$$

ï¼ˆç›´è§‚ä¸Šè¯´ï¼Œè¿™æ˜¯æŒ‡æˆ‘ä»¬çš„æ¨¡å‹**å¤±è´¥çš„æ­¥æ•°**æ˜¯ $\mathcal{O}(T^2)$ çš„ã€‚è™½ç„¶è¿™åªæ˜¯ä¸€ä¸ªä¸Šç•Œï¼Œä½† intuitively å®ƒåº”è¯¥æ˜¯æ¯”è¾ƒå‡†ç¡®çš„ã€‚ï¼‰

**Proof**. 

$$
S=\sum_{t\le T} E_{s_t\sim p_{\pi_\theta}}[c_t(s_t,a_t)]=\sum_{t\le T} \sum_{s_t}p_{\pi_\theta}(s_t)c_t(s_t,a_t)
$$

$$
\le \sum_{t\le T} \sum_{s_t}p_{\pi^\star}(s_t)\pi_\theta(a_t\ne \pi^\star(s_t)|s_t)+\sum_{t\le T} \sum_{s_t}|p_{\pi_\theta}(s_t)-p_{\pi^{\star}}(s_t)|c_t(s_t,a_t)
$$

ä½¿ç”¨ä¸Šä¸€ä¸ªç»“æœï¼Œæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°

$$
S\le \sum_{t\le T} \epsilon+\sum_{t\le T} 2\epsilon t = \mathcal{O}(\epsilon T^2).
$$

<!-- prettier-ignore-start -->
??? info "Tips"
    Take awayï¼Œvideoä¸­æœ‰è®²åˆ°ï¼Œå…¶å®rewardå‡½æ•°å’Œcostå‡½æ•°æ˜¯å¯ä»¥äº’æ¢çš„ï¼Œåªè¦æŠŠrewardå‡½æ•°å–è´Ÿå°±è¡Œäº†ã€‚
    ![20241031105631.png](graph/20241031105631.png)
<!-- prettier-ignore-end -->

# Make Bahavior Cloning Work

ä»‹ç»å‡ ä¸ªå¸¸è§çš„æ–¹æ³•ï¼Œè§£å†³bahavior cloningçš„è¿™ä¸ªé—®é¢˜ã€‚

## Adding Mistakes

![20241031104854.png](graph/20241031104854.png)
 
å‡è®¾æˆ‘ä»¬çš„æ¨¡å‹å­¦ä¼šæ”¹æ­£è‡ªå·±çš„é”™è¯¯ï¼ˆæ¯”å¦‚ï¼Œåœ¨èµ°é’¢ä¸çš„æ—¶å€™ï¼Œèº«ä½“å‘å·¦å€¾å€’çš„æ—¶åˆ»ï¼Œæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿè‡ªåŠ¨è°ƒæ•´èº«ä½“å‘å³å€¾å€’ï¼‰ã€‚è¿™æ ·çš„è¯ï¼ŒæˆåŠŸçš„æ¦‚ç‡ä¼šå¤§å¾ˆå¤šã€‚

ä¸€ä¸ªå…¸å‹çš„å®éªŒæ˜¯ï¼Œæˆ‘ä»¬åšä¸€ä¸ªé©¾é©¶çš„æ¨¡å‹ï¼Œç„¶ååšä¸‰ä¸ªæ‘„åƒå¤´ï¼šä¸€ä¸ªæ­£å¸¸çš„æ‘„åƒå¤´ï¼Œä¸€ä¸ªå‘å·¦åç§»çš„æ‘„åƒå¤´ï¼Œä¸€ä¸ªå‘å³åç§»çš„æ‘„åƒå¤´ã€‚åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œå·¦è¾¹æ‘„åƒå¤´çš„å›¾ç‰‡è¢«æ ‡è®°ä¸ºâ€œå³è½¬â€ï¼Œå³è¾¹æ‘„åƒå¤´çš„å›¾ç‰‡è¢«æ ‡è®°ä¸ºâ€œå·¦è½¬â€ã€‚è¿™æ ·çš„è¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°±èƒ½å¤Ÿå­¦ä¼šè‡ªåŠ¨è°ƒæ•´ã€‚

<!-- prettier-ignore-start -->
??? demo "çº¿ä»£æ¨¡å‹çš„ä¸€äº›ä»£è¡¨å·¥ä½œ"
    
    ![20241031105112.png](graph/20241031105112.png)
    ![20241031105125.png](graph/20241031105125.png)
    ![20241031105138.png](graph/20241031105138.png)
    ![20241031105154.png](graph/20241031105154.png)
    ![20241031105209.png](graph/20241031105209.png)
<!-- prettier-ignore-end -->

## Multi-task Learning

![20241031104419.png](graph/20241031104419.png)

è¿˜è®°å¾—æˆ‘ä»¬ä¹‹å‰çš„é—®é¢˜ï¼šåªè¦æ¨¡å‹ä¸€æ­¥è¯¯å…¥æ­§é€”ï¼Œæ¥ä¸‹æ¥å°±å†ä¹Ÿæ²¡æœ‰æŒ½å›çš„ä½™åœ°ã€‚å›é¡¾ä¸€ä¸‹ï¼Œä¹‹å‰çš„æ¨¡å‹å¤±è¯¯çš„æ—¶å€™ä¼šèµ°å‘ä¸€æ¡å…¨æ–°çš„é“è·¯ï¼Œæ˜¯å®Œå…¨æ²¡æœ‰è®­ç»ƒè¿‡çš„ï¼›ä½† multi-task learning å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜â€”â€”å®ƒé€šè¿‡å·§å¦™çš„è®¾è®¡æ”¶é›†å¤§é‡çš„ trajectory ä¿¡æ¯ï¼Œä½¿å¾—æ¨¡å‹åœ¨å“ªé‡Œéƒ½ä¸è‡³äºå®Œå…¨ä¸çŸ¥æ‰€æªã€‚

![20241031105315.png](graph/20241031105315.png)

å…·ä½“åœ°ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒçš„æ—¶å€™è®©ä¸“å®¶å¹¶éå‘å¾€ä¸€ä¸ªç›®æ ‡ $s_T$ å‰è¿›ï¼›ç›¸åï¼Œè®©å®ƒå¯¹å¾ˆå¤šä¸ª $s_T$ èµ°å¤šæ¡è¿™æ ·çš„è·¯å¾„ï¼š

$$
s_1,a_1,\cdots,s_{T-1},a_{T-1},s_T
$$

ç„¶åï¼Œæˆ‘ä»¬çš„æ•°æ®é›†æ”¶é›†

$$
\{(a_t|s_t,g_t=s_T)\}\in \mathcal{D}
$$

ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æ¨¡å‹çŸ¥é“äº†å¯¹äºæ¯ä¸€ä¸ª **ç›®æ ‡ $s_T$** åº”è¯¥æ¯ä¸€æ­¥æ€æ ·èµ°ã€‚è¿™æ ·çš„æ“ä½œä¹Ÿå«åš Goal-conditioned behavior cloningã€‚

<!-- prettier-ignore-start -->
??? example "ä¸€äº›ç°åœ¨çš„å·¥ä½œ"
    ![20241031105404.png](graph/20241031105404.png)
    ![20241031105419.png](graph/20241031105419.png)
    ![20241031105431.png](graph/20241031105431.png)
<!-- prettier-ignore-end -->

## DAgger

![20241031105459.png](graph/20241031105459.png)

DAggerä¹Ÿè¯•ç€è§£å†³åŸæ¥çš„é—®é¢˜ã€‚å®ƒçš„æ€è·¯æ˜¯ï¼Œä¸ºäº†é˜²æ­¢æ¨¡å‹èµ°é”™ä¹‹åä¸çŸ¥é“è¯¥æ€ä¹ˆèµ°ï¼Œæˆ‘ä»¬å°±åœ¨æ¯ä¸€ä¸ªè®­ç»ƒ iteration å®Œæˆä¹‹åè®©æ¨¡å‹è‡ªå·±è·‘ä¸€æ¬¡ï¼Œå¹¶è®©ä¸“å®¶æ¥æ ‡è®°æ­£ç¡®ç­”æ¡ˆã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬ä» $\pi_\theta$ ä¸­é‡‡æ ·

$$
s_1,a_1\sim \pi_\theta(\cdot|s_1),\cdots,s_T,a_T\sim \pi_\theta(\cdot|s_T)
$$

ç„¶åæŠŠè¿™äº›æ–°çš„æ•°æ®åŠ å…¥æ•°æ®é›†ä¸­ï¼š

$$
\mathcal{D}= \mathcal{D}\cup \left\{(s_t,a_t^\star=\pi^{\star}(s_t))|t=1,2,\cdots,T\right\}
$$

å½“ç„¶ï¼Œå®é™…ä¸Šå¯èƒ½é‡‡ç”¨ä¸€äº›å…¶ä»–ç­–ç•¥ï¼Œæ¯”å¦‚æ¯ä¸€æ¬¡ä¸æ˜¯åœ¨è¶Šæ¥è¶Šå¤§çš„æ•°æ®é›†ä¸Šå®Œæ•´åœ°è®­ç»ƒä¸€è½®ï¼Œè€Œæ˜¯æŠŠæ‰€æœ‰è®­ç»ƒçš„æ•°æ®å­˜åˆ°ä¸€ä¸ª buffer å†…éƒ¨ï¼Œç„¶åä»ä¸­éšæœºåœ°é‡‡æ ·ã€‚

å½“ç„¶ï¼Œ DAgger ä¹Ÿæœ‰å¾ˆæ˜¾è‘—çš„é—®é¢˜ï¼šéœ€è¦å¾ˆå¤šæ¬¡ä¸“å®¶è¿›è¡Œæ•°æ®çš„æ ‡æ³¨ï¼Œå› æ­¤è¿™éƒ¨åˆ†çš„ä»£ä»·å¯èƒ½ä¼šå¾ˆæ˜‚è´µã€‚

# Reference Papers

1. [A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning](https://arxiv.org/abs/1011.0686)